{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ffee72",
   "metadata": {},
   "source": [
    "# Validating Quality of Samples of Multivariate Gaussians Used in Simulations\n",
    "\n",
    "**1.** In order to verify the validity of the data we have generated we will show that it coroborates with known theoretical results. This section shows that our random number generation is unbiased using two methods. The first will graph the random variable defined as the maxima of standard normal process and compare it to the theoretical limit given by Extreme Value Theory. The second verifies that $\\mathbb{E}M_n$ grows asymptotically as is predicted by EVT.\n",
    "\n",
    "**2.** Second, we will verify that our simulations match the theoretical result that the DFGF of parameter $s=\\frac{1}{2}$ converges in distribution (in the sense of stochastic processes) to the Brownian Bridge. Using this, we will check that the distribution matches for large $n$ in addition to verifying that $\\mathbb{E}M_n$ converges to the theoretical limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b776aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For plotting data\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3a147",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "We need to import the following csv files to run statistical tests on them.\n",
    "\n",
    "### Sample Data\n",
    " - NumPy PCG64 Data\n",
    " - Jupyter PCG64 Data\n",
    " - (TO DO) SciPy QMC Multivariate Normal Data\n",
    "\n",
    "### Brownian Bridge Data\n",
    " - NumPy PCG64 Data\n",
    " - Jupyter PCG64 Data\n",
    " - (TO DO) SciPy QMC Multivariate Normal Data\n",
    "\n",
    "For some strange reason, it seems that generating the data using Jupyter Notebooks gives us higher quality (i.e. lower correlation) data for our simulations. Thus, we are considering reading the data in from CSV's after we pre-generate it in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a83a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Python SciPy Quasi-Monte-Carlo (QMC) Multivariate Normal Pre-Generated Data \"\"\"\n",
    "\n",
    "File = r\"~/FGF-manifold-simulator/Data/samples_SCIPY_MultivariateNormalQMC_n_10000_trials_20000.csv\"\n",
    "\n",
    "colnames=[f'{i}' for i in range(10000)]\n",
    "test_data = np.array(pd.read_csv(File, names=colnames))\n",
    "\n",
    "# compute the maximum of sample vector (that is the max of each row)\n",
    "# and store it in an array\n",
    "MaxData_SCIPY_MultivariateNormalQMC = np.amax(test_data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b72ac8",
   "metadata": {},
   "source": [
    "### Control Data\n",
    "For good measure, we also generate some random vectors using this notebook's PCG64 generator. Using this data, we compute the maximum of each vector sampled and store these values in an array to compare their quality with the other data generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480e07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON CONTROL DATA USING PCG64 - the modern one\n",
    "n=10000\n",
    "numTrials=20000\n",
    "\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "\n",
    "def computeMn_PCG64(nval):\n",
    "    vals=rng.standard_normal(nval)\n",
    "    return np.max(vals)\n",
    "\n",
    "def sampleMn_PCG64(nval, numTrials):\n",
    "    Mn_array = []\n",
    "    for j in range(numTrials):\n",
    "        Mn_array.append(computeMn_PCG64(nval))\n",
    "    return np.array(Mn_array)\n",
    "\n",
    "MaxData_Jupyter_PCG64_Control = sampleMn_PCG64(n,20000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a65f0",
   "metadata": {},
   "source": [
    "# Convergence in Distribution\n",
    "The first test we run verifies whether or not the sampled data agrees with the following fact:\n",
    "\n",
    "If $(X_n)_n{\\in\\mathbb{N}}$ is a sequence of i.i.d standard normal random variables, then the variable\n",
    "$M_n=\\max_{0\\leq j\\leq n} X_j$ obeys the following limit law:\n",
    "$$\n",
    "    \\mathbb{P}\\left(a_n(M_n-b_n)\\leq x\\right) \\xrightarrow{dist} \\exp(-\\exp(-x))\n",
    "$$\n",
    "where\n",
    "$$\n",
    "        a_n = \\sqrt{2\\log(n)} \\quad b_n = \\sqrt{2\\log(n)} - \\frac{1}{2}(2\\log(n)^{-\\frac{1}{2}}(\\log(\\log(n))+\\log(4\\pi))\n",
    "$$\n",
    "\n",
    "To test this, we will plot the maxima data that we collected from the various sources in histograms and check\n",
    "which datasets converge in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the pdf of limiting distribution of EM_n\n",
    "n=10000\n",
    "\n",
    "def a(n):\n",
    "    return np.sqrt(2*np.log(n))\n",
    "\n",
    "def b(n):\n",
    "    return np.sqrt(2*np.log(n)) - 0.5*pow(2*np.log(n), -0.5)*(np.log(np.log(n))+np.log(4*np.pi))\n",
    "\n",
    "def pdf(x):\n",
    "    return np.exp(-x-np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift data and scale accordingly by a(n) and b(n)\n",
    "MaxData_CPP_MT19937_Scaled = a(n)*(MaxData_CPP_MT19937-b(n))\n",
    "MaxData_CPP_Armadillo_Scaled = a(n)*(MaxData_CPP_Armadillo-b(n))\n",
    "MaxData_Jupyter_PCG64_Scaled = a(n)*(MaxData_Jupyter_PCG64-b(n))\n",
    "MaxData_Jupyter_PCG64_Control_Scaled = a(n)*(MaxData_Jupyter_PCG64_Control-b(n))\n",
    "MaxData_SCIPY_MultivariateNormalQMC_Scaled = a(n)*(MaxData_SCIPY_MultivariateNormalQMC-b(n))\n",
    "\n",
    "# create data for the X axis\n",
    "X=np.arange(-5.0,10.0,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10,10))\n",
    "ax1 = plt.subplot(111)\n",
    "\n",
    "hist=True\n",
    "\n",
    "# Plot the Histogram and Fitted PDF of the C++ MT19937 Data\n",
    "(counts1, bins1) = np.histogram(MaxData_CPP_MT19937_Scaled, bins=500)\n",
    "if hist:\n",
    "    plt.hist(bins1[:-1], bins1, weights=counts1, density=True, label=\"C++ MT19937\")\n",
    "beta1 = np.std(MaxData_CPP_MT19937_Scaled) * np.sqrt(6) / np.pi\n",
    "mu1 = np.mean(MaxData_CPP_MT19937_Scaled) - 0.57721*beta1\n",
    "plt.plot(bins1, (1/beta1)*np.exp(-(bins1 - mu1)/beta1)\n",
    "         * np.exp(-np.exp(-(bins1 - mu1)/beta1)),\n",
    "         linewidth=2, label=\"Fitted PDF C++ MT19917\")\n",
    "\n",
    "# Plot the Histogram and Fitted PDF of the C++ Armadillo Data\n",
    "(counts2, bins2) = np.histogram(MaxData_CPP_Armadillo_Scaled, bins=500)\n",
    "if hist:\n",
    "    plt.hist(bins2[:-1], bins2, weights=counts2, density=True, label=\"C++ Armadillo\")\n",
    "beta2 = np.std(MaxData_CPP_Armadillo_Scaled) * np.sqrt(6) / np.pi\n",
    "mu2 = np.mean(MaxData_CPP_Armadillo_Scaled) - 0.57721*beta2\n",
    "plt.plot(bins2, (1/beta2)*np.exp(-(bins2 - mu2)/beta2)\n",
    "         * np.exp(-np.exp(-(bins2 - mu2)/beta2)),\n",
    "         linewidth=2, label=\"Fitted PDF C++ Armadillo\")\n",
    "\n",
    "# Plot the Histogram and Fitted PDF of the C++ Generated Data\n",
    "(counts4, bins4) = np.histogram(MaxData_Jupyter_PCG64, bins=500)\n",
    "if hist:\n",
    "    plt.hist(bins4[:-1], bins4, weights=counts1, density=True, label=\"Jupyter PCG64 Pre-Computed\")\n",
    "beta4 = np.std(MaxData_Jupyter_PCG64) * np.sqrt(6) / np.pi\n",
    "mu4 = np.mean(MaxData_Jupyter_PCG64) - 0.57721*beta4\n",
    "plt.plot(bins4, (1/beta4)*np.exp(-(bins4 - mu4)/beta4)\n",
    "         * np.exp(-np.exp(-(bins4 - mu4)/beta4)),\n",
    "         linewidth=2, label=\"Fitted PDF Jupyter Pre-Computed\")\n",
    "\n",
    "# Plot the Histogram and Fitted PDF of the SciPy MultiVariateNormal Data\n",
    "(counts5, bins5) = np.histogram(MaxData_SCIPY_MultivariateNormalQMC_Scaled, bins=500)\n",
    "if hist:\n",
    "    plt.hist(bins5[:-1], bins5, weights=counts5, density=True, label=\"SciPy MultivariateNormalQMC\")\n",
    "beta5 = np.std(MaxData_SCIPY_MultivariateNormalQMC_Scaled) * np.sqrt(6) / np.pi\n",
    "mu5 = np.mean(MaxData_SCIPY_MultivariateNormalQMC_Scaled) - 0.57721*beta5\n",
    "plt.plot(bins5, (1/beta5)*np.exp(-(bins5 - mu5)/beta5)\n",
    "         * np.exp(-np.exp(-(bins5 - mu5)/beta5)),\n",
    "         linewidth=2, label=\"Fitted PDF SciPy MultivariateNormalQMC\")\n",
    "\n",
    "# Plot the Limit PDF of Gumbel and Histogram of Sample\n",
    "plt.plot(X, pdf(X), label=\"PDF of Gumbel Distribution\")\n",
    "if hist:\n",
    "    control_gumbel = np.random.gumbel(0, 1, 20000)\n",
    "    count, bins = np.histogram(control_gumbel, 500)\n",
    "    plt.hist(bins[:-1], bins, weights=count, density=True, label=\"Control Gumbel Histogram\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f23ba1",
   "metadata": {},
   "source": [
    "## Analysis of Different Random Number Engines:\n",
    "We can see that the pre-saved Jupyter Data is incredibly skewed, which disagrees with the expectation. Moreover, we see that the C++ built in MT19937 algorithm seems to give correlated data even when it has different seeds, yielding a higher expected value of $M_n$ and hence $a_n(M_n-b_n)$. Moreover, the pre-written NumPy PCG64 data appears to not be written correctly, giving larger results.\n",
    "\n",
    "**Takeaways: We see that SciPy and C++ Armadillo work well. For the forseeable future, we intend to use SciPy in our simulations on account of its ease of installation.**\n",
    "\n",
    "Other Notes\n",
    "- We would use Armadillo, but because we don't have root access on the HPC, any sort of installation of C++ packages is very time consuming. For the scope of this project, we intend to shift to Python\n",
    "- I noticed in the code that trent sent me to generate the Jupyter Pre-Computed PCG64 data, the new line delimiters were different, which makes me wonder if perhaps this caused an error in data processing.\n",
    "- Again, same thing with writing, reading, and parsing the NUMPY PCG64 Data. (UPDATE: For the time being I deleted this data since it was irrelevant).\n",
    "\n",
    "Below, we include some other figures that highlight the convergence of the C++ Armadillo data to the theoretical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "fig.suptitle('Comparison of Scaled Values of M_n against Gumbel Distribution')\n",
    "\n",
    "control = False\n",
    "\n",
    "# Plot the Limit PDF of Gumbel and Histogram of Sample\n",
    "ax1.plot(X, pdf(X), label=\"PDF of Gumbel Distribution\")\n",
    "ax2.plot(X, pdf(X), label=\"PDF of Gumbel Distribution\")\n",
    "control_gumbel = np.random.gumbel(0, 1, 20000)\n",
    "count, bins = np.histogram(control_gumbel, 500)\n",
    "ax1.hist(bins[:-1], bins, weights=count, density=True, label=\"Control Gumbel Histogram\")\n",
    "\n",
    "if control:\n",
    "    # Plot the Histogram and Fitted PDF of the Control Jupyter PCG64 Randomly Generated Numbers\n",
    "    (counts3, bins3) = np.histogram(MaxData_Jupyter_PCG64_Control_Scaled, bins=500)\n",
    "    ax1.hist(bins3[:-1], bins3, weights=counts3, density=True, label=\"Control Jupyter PCG64\")\n",
    "    beta3 = np.std(MaxData_Jupyter_PCG64_Control_Scaled) * np.sqrt(6) / np.pi\n",
    "    mu3 = np.mean(MaxData_Jupyter_PCG64_Control_Scaled) - 0.57721*beta3\n",
    "    ax1.plot(bins3, (1/beta3)*np.exp(-(bins3 - mu3)/beta3)\n",
    "             * np.exp(-np.exp(-(bins3 - mu3)/beta3)),\n",
    "             linewidth=2, label=\"Fitted PDF Control Jupyter PCG64\")\n",
    "    ax2.plot(bins3, (1/beta3)*np.exp(-(bins3 - mu3)/beta3)\n",
    "             * np.exp(-np.exp(-(bins3 - mu3)/beta3)),\n",
    "             linewidth=2, label=\"Fitted PDF Control Jupyter PCG64\")\n",
    "\n",
    "# Plot the Histogram and Fitted PDF of the Control Jupyter PCG64 Randomly Generated Numbers\n",
    "(counts4, bins4) = np.histogram(MaxData_SCIPY_MultivariateNormalQMC_Scaled, bins=500)\n",
    "ax1.hist(bins4[:-1], bins4, weights=counts4, density=True, label=\"SciPy MultivariateNormalQMC\")\n",
    "beta4 = np.std(MaxData_SCIPY_MultivariateNormalQMC_Scaled) * np.sqrt(6) / np.pi\n",
    "mu4 = np.mean(MaxData_SCIPY_MultivariateNormalQMC_Scaled) - 0.57721*beta4\n",
    "ax1.plot(bins4, (1/beta4)*np.exp(-(bins4 - mu4)/beta4)\n",
    "         * np.exp(-np.exp(-(bins4 - mu4)/beta4)),\n",
    "         linewidth=2, label=\"SciPy MultivariateNormalQMC\")\n",
    "ax2.plot(bins4, (1/beta4)*np.exp(-(bins4 - mu4)/beta4)\n",
    "         * np.exp(-np.exp(-(bins4 - mu4)/beta4)),\n",
    "         linewidth=2, label=\"SciPy MultivariateNormalQMC\")\n",
    "\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13566b",
   "metadata": {},
   "source": [
    "# Expected Value as n Increases\n",
    "We know from Leadbetter et. al. that if $(X_n)_{n\\in\\mathbb{N}}$ is a sequence of $\\mathcal{N}(0,1)$\n",
    "i.i.d variables and $M_n=\\max_{0\\leq j\\leq n}X_j$, then\n",
    "$$\n",
    "\\mathbb{E}M_n \\approx \\sqrt(2\\log(n)-\\frac{1}{2}(2\\log(n))^{-\\frac{1}{2}}(\\log\\log(n)+\\log(4\\pi))\n",
    "$$\n",
    "Using this, we can plot and compare the empirical value of $\\mathbb{E}M_n$ against the known\n",
    "theoretical value. As it turns out, the empirical data that we generated agrees with the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319df25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "File = r'/Users/connormarrs/Math/FGF-manifold-simulator/Data/MaxDist/gaussian_expected_maxima50000.csv'\n",
    "\n",
    "colnames=['n', 'exp'] \n",
    "data = pd.read_csv(File, names=colnames)\n",
    "\n",
    "EXP = np.array(data['exp'])\n",
    "N = np.array(data['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Python EMn data\n",
    "def sample_EMn(numTrials):\n",
    "    EMn_array = []\n",
    "    for n in N:\n",
    "        EMn_array.append(\n",
    "            np.mean(sampleMn_PCG64(n, numTrials))\n",
    "        )\n",
    "    return EMn_array\n",
    "\n",
    "Control_Exp_Data_PCG64 = sample_EMn(2000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d013663",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10,10))\n",
    "plt.scatter(N,Control_Exp_Data_PCG64, label=\"Python PCG64 Control\")\n",
    "plt.scatter(N, EXP, label=\"C++ MT19937 Data\")\n",
    "plt.scatter(N, np.sqrt(2*np.log(N)), label=\"Naive Approximation sqrt(2log(n))\")\n",
    "plt.scatter(N, b(N), label=\"Theoretical Asymptote given by b(n)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13100735",
   "metadata": {},
   "source": [
    "# Brownian Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "File = r'/Users/connormarrs/Math/gaussian-free-fields-reu/data/MaxDist/2500_0.500000.csv'\n",
    "\n",
    "colnames=['max', 'exp'] \n",
    "data = pd.read_csv(File, names=colnames)\n",
    "\n",
    "MaxData = list(data['max'])\n",
    "M = data['exp'][0]\n",
    "\n",
    "Diff = []\n",
    "\n",
    "for x in range(len(MaxData)):\n",
    "    Diff.append(MaxData[x] - M)\n",
    "    \n",
    "fig = plt.figure(figsize =(10,10))\n",
    "ax1 = plt.subplot(111)\n",
    "\n",
    "ax1.hist(x=MaxData, bins=int(np.floor(len(MaxData)*.05)))\n",
    "ax1.plot(P, BPDF(P))\n",
    "plt.show()\n",
    "\n",
    "def BPDF(x):\n",
    "    return (4*x/np.pi)*np.exp((-2*x**2)/(np.pi))\n",
    "\n",
    "P = [x for x in range(0,3)]\n",
    "\n",
    "P = np.array(P)\n",
    "\n",
    "address = '/Users/connormarrs/Math/gaussian-free-fields-reu/data/Maxima'\n",
    "\n",
    "# min N, Max N, step-size\n",
    "N_Data = ['500','1950','10']\n",
    "\n",
    "# min S, max S, step-size\n",
    "S_Data = ['0.0','0.5','.001']\n",
    "\n",
    "# creates a variable for the .format() function which call specified files in \\Maxima\n",
    "Folder = address + '/{}_s0.0-0.5.csv'\n",
    "\n",
    "# For some reason trying to create mlist in the function above breaks things\n",
    "nlist = []\n",
    "slist = []\n",
    "mlist = []\n",
    "\n",
    "for n in range(int(N_Data[0]), int(N_Data[1])+int(N_Data[2]), int(N_Data[2])):\n",
    "    filenew = Folder.format(n)\n",
    "    \n",
    "    colnames=['n', 's','m'] \n",
    "    numbers = pd.read_csv(filenew, names=colnames)\n",
    "    \n",
    "    nlist.append(list(numbers['n']))\n",
    "    slist.append(list(numbers['s']))\n",
    "    mlist.append(list(numbers['m']))\n",
    "    \n",
    "S = .5\n",
    "\n",
    "# The index function tells us the index of our S value so we can ensure a proper zip with the future m values\n",
    "Index = slist[0].index(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaebb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nFixed = []\n",
    "mFixed = []\n",
    "\n",
    "for s in range(len(slist)):\n",
    "    if S in slist[s]:\n",
    "        nFixed.append(nlist[s][Index])\n",
    "        mFixed.append(mlist[s][Index])\n",
    "        \n",
    "nFixed = np.array(nFixed)\n",
    "mFixed = np.array(mFixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymptotic(x):\n",
    "    return np.sqrt(np.pi/2)*np.pi/(2*np.sqrt(2))\n",
    "\n",
    "asymptotic_array = []\n",
    "\n",
    "for x in range(len(nFixed)):\n",
    "    asymptotic_array.append(asymptotic(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "f = plt.figure(figsize = (12,8))\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.set_ylim(0,int(np.ceil(max(mFixed)))+1)\n",
    "\n",
    "ax1.scatter(nFixed, mFixed, c='blue')\n",
    "ax1.plot(nFixed, asymptotic_array, c='green')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
